### 1. So sánh Các Định Dạng Model AI

| **Tên (Extension)**                       | **Điểm mạnh**                                                                                                                                         | **Điểm yếu**                                                                                                                         | **Quá trình hình thành & Phát triển**                                                                                                                                                                                                      |
|-------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **ONNX (.onnx)**                          | - Mã nguồn mở, hỗ trợ chuyển đổi mô hình giữa nhiều framework (như TensorFlow, PyTorch, Keras, ...).                                                  | - Đôi khi gặp khó khăn trong việc tối ưu hóa hiệu suất khi triển khai trên các thiết bị cụ thể.                                       | Được phát triển từ sự hợp tác của các ông lớn như Microsoft và Facebook nhằm tạo ra tiêu chuẩn trao đổi mô hình. Qua thời gian, ONNX liên tục được cải tiến và mở rộng tích hợp với nhiều hệ sinh thái.                               |
| **TensorFlow SavedModel (saved_model.pb)** | - Tích hợp chặt chẽ với hệ sinh thái TensorFlow.<br>- Hỗ trợ triển khai đa nền tảng, từ thiết bị di động, web cho đến server và cloud.                  | - Phức tạp khi cần chuyển đổi sang framework khác, do chủ yếu tối ưu cho TensorFlow.                                                | Là định dạng chủ đạo của TensorFlow, được Google phát triển từ năm 2015 và liên tục cải tiến để đáp ứng nhu cầu triển khai và sản xuất hiện đại.                                                                                           |
| **PyTorch (.pt/.pth)**                    | - Linh hoạt nhờ đồ thị tính toán động, giúp debug và thử nghiệm dễ dàng.<br>- Phổ biến trong cộng đồng nghiên cứu và phát triển.                      | - Ít thuận tiện trong việc chuyển đổi sang các framework khác so với ONNX.                                                         | Phát triển cùng với PyTorch (ra đời năm 2016), định dạng này đã trở nên quen thuộc với các nhà nghiên cứu nhờ tính trực quan và khả năng bảo trì mô hình.                                                                              |
| **GGUF (.gguf)**                          | - Tăng tốc độ tải và khởi động mô hình.<br>- Được tối ưu cho các mô hình ngôn ngữ lớn với yêu cầu tài nguyên thấp.                                     | - Đang trong giai đoạn phát triển, có thể chưa ổn định cho một số ứng dụng.                                                         | Mới được ra đời nhằm tối ưu hóa hiệu suất cho các LLM (large language models) khi chạy trên các thiết bị có tài nguyên hạn chế, đáp ứng xu thế ứng dụng thực tiễn với hiệu năng cao.                                                 |
| **Safetensors (.safetensors)**            | - Đảm bảo an toàn và bảo mật cao khi lưu trữ và chia sẻ mô hình.<br>- Giúp giảm nguy cơ lỗi hoặc tấn công qua tập tin mô hình.                          | - Chưa được tích hợp rộng rãi trong một số quy trình chuyển đổi định dạng.                                                         | Ra đời gần đây với mục tiêu tăng cường an toàn khi phân phối mô hình AI, đặc biệt trong bối cảnh an ninh thông tin ngày càng được quan tâm.                                                                                                  |
| **Core ML (.mlmodel)**                    | - Tối ưu cho hệ sinh thái Apple (iOS, macOS).<br>- Dễ tích hợp trực tiếp vào ứng dụng trên thiết bị của Apple.                                       | - Giới hạn sử dụng chủ yếu trong hệ sinh thái của Apple, khó chuyển đổi sang các nền tảng khác.                                      | Phát triển bởi Apple nhằm mang lại khả năng tích hợp mô hình AI trực tiếp lên thiết bị di động và máy tính của họ, đồng thời liên tục cập nhật theo tiến bộ của phần cứng và phần mềm trong hệ sinh thái độc quyền của Apple.             |

---

### 2. So sánh Các Framework AI

| **Tên**                             | **Điểm mạnh**                                                                                                                                         | **Điểm yếu**                                                                                                                         | **Quá trình hình thành & Phát triển**                                                                                                                                                                                                     |
|-------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **TensorFlow**                      | - Hỗ trợ đa nền tảng, từ server đến thiết bị di động (TF Lite, TF.js).<br>- Hệ sinh thái phong phú, được doanh nghiệp và cộng đồng nghiên cứu ưa chuộng. | - Ít linh hoạt trong nghiên cứu so với PyTorch.                    | Được Google phát triển từ năm 2015, TensorFlow trải qua nhiều phiên bản cải tiến (TF 1.x → 2.x) nhằm tối ưu hóa khả năng triển khai và đáp ứng nhu cầu nghiên cứu.                                                            |
| **PyTorch**                         | - Đồ thị tính toán động trực quan, dễ debug và thử nghiệm.<br>- Phổ biến trong cộng đồng nghiên cứu với nhiều tài nguyên hỗ trợ phát triển.           | - Ban đầu còn hạn chế về triển khai sản xuất.<br>- Đòi hỏi hiểu biết sâu sắc để tối ưu hiệu năng trên một số ứng dụng.               | Ra đời vào năm 2016 bởi Meta (Facebook), PyTorch đã nhanh chóng trở thành lựa chọn hàng đầu của cộng đồng nghiên cứu nhờ tính linh hoạt và khả năng thử nghiệm các mô hình deep learning tiên tiến.                      |
| **Transformers**       | - Dễ tích hợp các mô hình transformer tiên tiến cho NLP.<br>- Hỗ trợ đa dạng các tác vụ xử lý ngôn ngữ tự nhiên với kho mô hình liên tục được cập nhật.  | - Chủ yếu tập trung vào các mô hình transformer, hạn chế đối với các ứng dụng ngoài xử lý ngôn ngữ tự nhiên.                         | Phát triển nhằm đáp ứng nhu cầu ứng dụng các mô hình transformer hiện đại trong NLP, thư viện đã nhanh chóng trở thành tiêu chuẩn cho các giải pháp xử lý ngôn ngữ tự nhiên tiên tiến.                                   |
| **OpenVINO**                        | - Tối ưu hóa hiệu suất inference trên CPU và các thiết bị Intel (bao gồm FPGA).<br>- Cung cấp công cụ chuyển đổi và tối ưu hóa mô hình cho phần cứng chuyên dụng. | - Tối ưu chủ yếu cho phần cứng Intel, gây hạn chế khi triển khai trên các nền tảng phần cứng khác.                                   | Được Intel phát triển nhằm tối ưu hóa quá trình inference của các mô hình deep learning trên phần cứng của mình, OpenVINO liên tục được cập nhật để hỗ trợ nhiều mô hình và ứng dụng trong ngành công nghiệp.            |
| **Bitnet**                          | - Tối ưu cho hiệu suất trên CPU với khả năng chạy các mô hình lớn mà không cần GPU cao cấp.<br>- Áp dụng công nghệ lượng tử hóa (ternary quantization) giúp tiết kiệm tài nguyên.               | - Công nghệ tương đối mới, cần thêm thời gian kiểm chứng hiệu suất trong các ứng dụng quy mô rộng.                                    | Phát triển bởi Microsoft nhằm cung cấp giải pháp chạy mô hình AI hiệu quả trên CPU, Bitnet tập trung vào tối ưu hóa hiệu năng và giảm tiêu thụ tài nguyên, mở ra hướng đi mới cho các ứng dụng trên thiết bị có cấu hình hạn chế. |

---

### 3. So sánh Các Loại Chip Chạy Model AI

| **Loại Chip**                                      | **Điểm mạnh**                                                                                                                                               | **Điểm yếu**                                                                                                                 | **Quá trình hình thành & Phát triển**                                                                                                                                                                                                                                                                           |
|----------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **CPU (Central Processing Unit)**                | - Linh hoạt, có khả năng xử lý nhiều loại tác vụ khác nhau.<br>- Được tích hợp rộng rãi trên mọi máy tính, dễ truy cập và sử dụng.                           | - Kiến trúc không tối ưu cho tính toán song song quy mô lớn, hiệu năng cho deep learning kém hơn so với GPU.                   | Công nghệ CPU đã phát triển từ những năm 1970, tiến hóa từ kiến trúc đơn nhân sang đa nhân để đáp ứng yêu cầu xử lý đồng thời của các hệ thống hiện đại.                                                                                                                                        |
| **GPU (Graphics Processing Unit)**               | - Cấu trúc song song với hàng nghìn lõi, rất phù hợp cho các phép tính ma trận và tensor trong deep learning.<br>- Hiệu năng vượt trội trong training và inference. | - Tiêu thụ năng lượng cao, thường cần hệ thống làm mát chuyên dụng.<br>- Chi phí đầu tư ban đầu thường khá lớn.              | Ban đầu được thiết kế cho đồ họa và xử lý hình ảnh trong game, GPU sau đó đã chuyển mình trở thành xương sống của các ứng dụng AI hiện đại với sự ra đời của các kiến trúc tiên tiến từ Nvidia, AMD,…                                                                     |
| **TPU (Tensor Processing Unit)**                 | - Được tối ưu đặc biệt cho các tác vụ deep learning với hiệu năng tính toán cao.<br>- Tiết kiệm điện năng hơn so với GPU khi thực hiện các phép tính chuyên biệt.    | - Hạn chế trong việc tích hợp, chủ yếu hỗ trợ hệ sinh thái TensorFlow của Google.                                          | TPU được Google phát triển từ năm 2016 nhằm tăng tốc các tác vụ học sâu trong các trung tâm dữ liệu của họ. Qua nhiều thế hệ cải tiến, TPU đã chứng tỏ hiệu quả cao trong việc xử lý các mô hình phức tạp với khả năng mở rộng trên quy mô lớn.                                    |
| **NPU / AI Accelerator (Neural Processing Unit)** | - Tối ưu cho các tác vụ inference AI, tiêu thụ năng lượng thấp.<br>- Được tích hợp vào chip của thiết bị di động (ví dụ: Apple Neural Engine, Qualcomm AI Engine). | - Khả năng xử lý hạn chế đối với các tác vụ training lớn so với GPU hay TPU.<br>- Bộ nhớ và hiệu năng xử lý bị giới hạn trong môi trường nhúng. | Với sự bùng nổ của AI trên thiết bị di động, NPU ra đời nhằm mang lại khả năng xử lý AI nội bộ cho smartphone, tablet và IoT. Những chip này giúp thực hiện các tác vụ inference nhanh chóng mà không cần phụ thuộc vào phần cứng rời, thích hợp cho các ứng dụng tiêu thụ năng lượng thấp. |
| **FPGA (Field Programmable Gate Array)**          | - Có thể cấu hình lại linh hoạt theo yêu cầu ứng dụng, phù hợp với nhiều thuật toán cụ thể.<br>- Hiệu quả năng lượng tốt cho các tác vụ thời gian thực.   | - Yêu cầu kiến thức chuyên sâu trong lập trình vi mạch, thời gian và chi phí phát triển tích hợp cao.                         | Ra đời từ những năm 1980, FPGA ban đầu được sử dụng trong các ứng dụng công nghiệp và viễn thông. Hiện nay, FPGA đang được ứng dụng trong các trung tâm dữ liệu và hệ thống nhúng cần cấu hình phần cứng tùy biến theo từng bài toán.                                             |
| **ASIC (Application-Specific Integrated Circuit)** | - Được thiết kế cho một nhiệm vụ cụ thể, mang lại hiệu năng vượt trội và tiêu thụ năng lượng cực thấp.<br>- Chi phí vận hành sau sản xuất thấp.         | - Chi phí nghiên cứu và phát triển ban đầu rất cao.<br>- Thiếu tính linh hoạt, không thể tái lập trình khi yêu cầu thay đổi.   | ASIC được chế tạo để thực hiện các tác vụ nhất định với hiệu năng tối ưu. Ví dụ điển hình là các chip chuyên dụng trong các trung tâm dữ liệu lớn (như Google TPU) hay các ứng dụng AI công nghiệp, nơi mà hiệu quả và hiệu năng được đặt lên hàng đầu.                                     |
| **Neuromorphic Chips**                           | - Thiết kế mô phỏng hoạt động của não, hứa hẹn tiêu thụ năng lượng cực thấp và xử lý song song hiệu quả.<br>- Có tiềm năng cách mạng hóa kiến trúc xử lý AI. | - Công nghệ vẫn đang trong giai đoạn nghiên cứu, chưa phổ biến và ứng dụng thương mại rộng rãi.<br>- Hiệu năng và khả năng lập trình chưa tối ưu so với các giải pháp truyền thống. | Neuromorphic chips được nghiên cứu với mục tiêu xây dựng các hệ thống xử lý theo mô hình thần kinh của con người. Dù còn đang trong giai đoạn thử nghiệm, những nỗ lực này hứa hẹn mang lại bước đột phá về hiệu năng và tiết kiệm năng lượng cho các ứng dụng AI trong tương lai.             |

---

### 4. So sánh các định dạng model AI theo khía cạnh hiệu năng trên các loại chip

| **Định dạng (Extension)**                 | **Chip Tối Ưu**                                                                                                                                   | **Chip Không Tối Ưu**                                                                                 | **Ghi chú**                                                                                                                                                                                                                                              |
|-------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **ONNX (.onnx)**                          | CPU và GPU (bao gồm Nvidia CUDA, AMD ROCm) khi sử dụng các runtime tối ưu (như ONNX Runtime, TensorRT).                                            | TPU và một số accelerator chuyên dụng có thể chưa được hỗ trợ nguyên bản, đòi hỏi cấu hình thêm.       | Là định dạng trung lập, cho phép chuyển đổi giữa nhiều framework. Hiệu năng phụ thuộc vào runtime và thư viện tối ưu được tích hợp vào hệ thống của chip.                                                                                         |
| **TensorFlow SavedModel (saved_model.pb)** | TPU và GPU khi chạy trong hệ sinh thái TensorFlow; cũng tối ưu cho CPU nếu được biên dịch và tối ưu hóa thông qua các kỹ thuật giảm độ chính xác. | Trên các nền tảng không dùng TensorFlow (ví dụ: thiết bị di động không chuyển đổi sang TFLite)         | Tích hợp sâu trong hệ sinh thái TensorFlow của Google, thích hợp cho các tác vụ đào tạo quy mô lớn và inference trong môi trường chuyên dụng.                                                                                                             |
| **PyTorch (.pt/.pth)**                    | GPU (Nvidia CUDA, AMD thông qua ROCm) và CPU – đặc biệt khi dùng TorchScript hoặc các kỹ thuật quantization để tối ưu cho inference.              | Các thiết bị nhúng hoặc di động nếu không chuyển đổi sang định dạng chuyên dụng (ví dụ: qua Torch Mobile). | Dù phát triển chủ yếu cho các tác vụ training trên GPU, PyTorch có khả năng chạy trên nhiều nền tảng; tuy nhiên, để đạt hiệu năng tối ưu trên thiết bị di động cần qua các bước chuyển đổi và tối ưu hóa đặc thù.                                      |
| **GGUF (.gguf)**                          | CPU, đặc biệt cho inference của các LLM (large language models) trong môi trường có tài nguyên hạn chế.                                               | GPU không phải là mục tiêu chính, cũng như các hệ thống dành cho đào tạo quy mô lớn.                   | Định dạng mới phát triển với trọng tâm là giảm kích thước và tăng tốc độ tải, chủ yếu được “nén” để chạy hiệu quả trên CPU với bộ nhớ hạn chế.                                                                                                        |
| **Safetensors (.safetensors)**            | Hoạt động tốt trên mọi nền tảng (CPU, GPU) vì chỉ là dạng lưu trữ trọng số an toàn, giúp tải nhanh và giảm rủi ro truy cập dữ liệu.                    | –                                                                                                     | Không chứa kiến trúc tính toán nên hiệu năng chủ yếu phụ thuộc vào runtime sử dụng. Điều này có nghĩa là nó không “tối ưu” hay “hạn chế” theo chip, mà chủ yếu giúp an toàn và tốc độ tải trọng số trong quá trình inference hoặc training.             |
| **Core ML (.mlmodel)**                    | Các thiết bị của Apple – sử dụng hiệu quả Apple Neural Engine, GPU tích hợp và CPU trên iOS, macOS.                                                 | Các nền tảng ngoài hệ sinh thái Apple (ví dụ: Windows, Android) không thể chạy trực tiếp.             | Định dạng này được thiết kế riêng cho hệ sinh thái Apple, giúp tối ưu hóa hiệu năng và tiết kiệm năng lượng trên các thiết bị của Apple, nhưng không có tính chuyển giao cao sang hệ thống khác nếu không qua chuyển đổi.                           |

---
